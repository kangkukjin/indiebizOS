"""
ìŒì„± ì…ì¶œë ¥ í‘œì¤€ ë„êµ¬ (Whisper Small ë²„ì „)
Standard Tool for Voice Input/Output with Whisper

Commands:
- listen: ìŒì„± ì…ë ¥ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (Whisper Small ì‚¬ìš©)
- speak: í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ì¶œë ¥
- start_listening: ì—°ì† ìŒì„± ì…ë ¥ ëª¨ë“œ ì‹œì‘
- stop_listening: ì—°ì† ìŒì„± ì…ë ¥ ëª¨ë“œ ì¤‘ì§€
"""

import speech_recognition as sr
import pyttsx3
import threading
import queue
import time
import whisper
import numpy as np

class VoiceIO:
    def __init__(self):
        # ìŒì„± ì¸ì‹ê¸° ì´ˆê¸°í™”
        self.recognizer = sr.Recognizer()
        self.microphone = sr.Microphone()
        
        # Whisper ëª¨ë¸ ë¡œë“œ (small ëª¨ë¸ - í•œêµ­ì–´ ì¸ì‹ í•„ìˆ˜)
        try:
            print("ğŸ”„ Whisper Small ëª¨ë¸ ë¡œë”© ì¤‘...")
            self.whisper_model = whisper.load_model("small")
            self.use_whisper = True
            print("âœ… Whisper Small ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ì˜¤í”„ë¼ì¸ STT)")
        except Exception as e:
            print(f"âš ï¸ Whisper ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("   â†’ Google APIë¡œ í´ë°±í•©ë‹ˆë‹¤")
            self.use_whisper = False
        
        # ìŒì„± í•©ì„± ì—”ì§„ ì´ˆê¸°í™”
        self.tts_engine = pyttsx3.init()
        self.tts_engine.setProperty('rate', 150)  # ì†ë„
        self.tts_engine.setProperty('volume', 0.9)  # ë³¼ë¥¨
        
        # í•œêµ­ì–´ ìŒì„± ì„¤ì • (ê°€ëŠ¥í•œ ê²½ìš°)
        voices = self.tts_engine.getProperty('voices')
        for voice in voices:
            if 'korean' in voice.name.lower() or 'ko' in voice.languages:
                self.tts_engine.setProperty('voice', voice.id)
                break
        
        # ì—°ì† ë“£ê¸° ëª¨ë“œ
        self.is_listening = False
        self.listen_thread = None
        self.audio_queue = queue.Queue()
        
        # ë§ˆì´í¬ ë…¸ì´ì¦ˆ ì¡°ì •
        with self.microphone as source:
            self.recognizer.adjust_for_ambient_noise(source, duration=1)
        
        # ì—ë„ˆì§€ ì„ê³„ê°’ ìˆ˜ë™ ì„¤ì • (ë§¤ìš° ë‚®ê²Œ)
        self.recognizer.energy_threshold = 100  # ë§¤ìš° ë‚®ê²Œ ì„¤ì • (MacBook Air ë§ˆì´í¬ìš©)
        self.recognizer.dynamic_energy_threshold = False  # ê³ ì • ì„ê³„ê°’ ì‚¬ìš©
        self.recognizer.pause_threshold = 0.5  # ë§ ë©ˆì¶¤ ê°ì§€ ì‹œê°„ ë‹¨ì¶• (0.8 â†’ 0.5ì´ˆ)
    
    def listen_once(self, language='ko-KR', timeout=5):
        """
        í•œ ë²ˆ ìŒì„± ì…ë ¥ ë°›ê¸° (Whisper ë˜ëŠ” Google API)
        
        Args:
            language: ì¸ì‹ ì–¸ì–´ (ê¸°ë³¸ê°’: í•œêµ­ì–´)
            timeout: ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
        
        Returns:
            ì¸ì‹ëœ í…ìŠ¤íŠ¸ ë˜ëŠ” None
        """
        try:
            with self.microphone as source:
                print("ğŸ¤ ë“£ê³  ìˆìŠµë‹ˆë‹¤... (ì„ê³„ê°’: {})" .format(self.recognizer.energy_threshold))
                print("   í° ì†Œë¦¬ë¡œ ë§ì”€í•˜ì„¸ìš”!")
                
                audio = self.recognizer.listen(source, timeout=timeout, phrase_time_limit=10)
                
            print("ğŸ”„ ìŒì„± ì¸ì‹ ì¤‘...")
            
            # Whisper ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ ìš°ì„  ì‚¬ìš©
            if self.use_whisper:
                # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
                audio_data = np.frombuffer(audio.get_raw_data(), np.int16)
                audio_float = audio_data.astype(np.float32) / 32768.0

                # ìƒ˜í”Œë ˆì´íŠ¸ ë³€í™˜ (WhisperëŠ” 16kHz í•„ìš”)
                sample_rate = audio.sample_rate
                if sample_rate != 16000:
                    import soxr
                    audio_float = soxr.resample(audio_float, sample_rate, 16000)

                # Whisperë¡œ ì¸ì‹
                lang_code = 'ko' if language.startswith('ko') else 'en'
                result = self.whisper_model.transcribe(
                    audio_float,
                    language=lang_code,
                    fp16=False  # CPU ì‚¬ìš© ì‹œ
                )
                text = result['text'].strip()
                print(f"âœ… ì¸ì‹ë¨ (Whisper): {text}")
                return text
            else:
                # í´ë°±: Google API
                text = self.recognizer.recognize_google(audio, language=language)
                print(f"âœ… ì¸ì‹ë¨ (Google): {text}")
                return text
            
        except sr.WaitTimeoutError:
            print("â±ï¸ íƒ€ì„ì•„ì›ƒ: ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        except sr.UnknownValueError:
            print("âŒ ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        except sr.RequestError as e:
            print(f"âŒ ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {e}")
            return None
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")
            return None
    
    def speak(self, text):
        """
        í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ì¶œë ¥
        
        Args:
            text: ì¶œë ¥í•  í…ìŠ¤íŠ¸
        """
        try:
            print(f"ğŸ”Š ë§í•˜ê¸°: {text}")
            self.tts_engine.say(text)
            self.tts_engine.runAndWait()
            return True
        except Exception as e:
            print(f"âŒ ìŒì„± ì¶œë ¥ ì˜¤ë¥˜: {e}")
            return False
    
    def start_continuous_listening(self, language='ko-KR'):
        """ì—°ì† ë“£ê¸° ëª¨ë“œ ì‹œì‘"""
        if self.is_listening:
            return False
        
        self.is_listening = True
        self.listen_thread = threading.Thread(
            target=self._continuous_listen_loop,
            args=(language,),
            daemon=True
        )
        self.listen_thread.start()
        print("ğŸ¤ ì—°ì† ë“£ê¸° ëª¨ë“œ ì‹œì‘")
        return True
    
    def stop_continuous_listening(self):
        """ì—°ì† ë“£ê¸° ëª¨ë“œ ì¤‘ì§€"""
        if not self.is_listening:
            return False
        
        self.is_listening = False
        if self.listen_thread:
            self.listen_thread.join(timeout=2)
        print("ğŸ›‘ ì—°ì† ë“£ê¸° ëª¨ë“œ ì¤‘ì§€")
        return True
    
    def _continuous_listen_loop(self, language):
        """ì—°ì† ë“£ê¸° ë£¨í”„ (ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ)"""
        while self.is_listening:
            try:
                with self.microphone as source:
                    audio = self.recognizer.listen(source, timeout=1, phrase_time_limit=10)
                    
                # Whisper ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ ìš°ì„  ì‚¬ìš©
                if self.use_whisper:
                    audio_data = np.frombuffer(audio.get_raw_data(), np.int16)
                    audio_float = audio_data.astype(np.float32) / 32768.0
                    lang_code = 'ko' if language.startswith('ko') else 'en'
                    result = self.whisper_model.transcribe(
                        audio_float, 
                        language=lang_code,
                        fp16=False
                    )
                    text = result['text'].strip()
                    self.audio_queue.put(text)
                else:
                    # í´ë°±: Google API
                    text = self.recognizer.recognize_google(audio, language=language)
                    self.audio_queue.put(text)
            except sr.WaitTimeoutError:
                continue
            except sr.UnknownValueError:
                continue
            except Exception as e:
                print(f"âŒ ì—°ì† ë“£ê¸° ì˜¤ë¥˜: {e}")
                time.sleep(0.1)
    
    def get_recognized_text(self):
        """íì—ì„œ ì¸ì‹ëœ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
        try:
            return self.audio_queue.get_nowait()
        except queue.Empty:
            return None


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_voice_io = None

def get_voice_io():
    """VoiceIO ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
    global _voice_io
    if _voice_io is None:
        _voice_io = VoiceIO()
    return _voice_io


def tool_voice_io(command, send_to=None, comment=None, text=None, language='ko-KR', timeout=5):
    """
    ìŒì„± ì…ì¶œë ¥ í‘œì¤€ ë„êµ¬
    
    Args:
        command: ëª…ë ¹ì–´
            - "listen": í•œ ë²ˆ ìŒì„± ì…ë ¥ ë°›ê¸°
            - "speak": í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ì¶œë ¥
            - "start_listening": ì—°ì† ë“£ê¸° ì‹œì‘
            - "stop_listening": ì—°ì† ë“£ê¸° ì¤‘ì§€
            - "get_text": ì¸ì‹ëœ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (ì—°ì† ë“£ê¸° ëª¨ë“œ)
        send_to: ë‹¤ìŒ ë„êµ¬ (í‘œì¤€ ë„êµ¬ íŒ¨í„´)
        comment: ì£¼ì„
        text: speak ëª…ë ¹ì‹œ ì¶œë ¥í•  í…ìŠ¤íŠ¸
        language: ì¸ì‹ ì–¸ì–´ (ê¸°ë³¸ê°’: ko-KR)
        timeout: listen ëª…ë ¹ì‹œ ìµœëŒ€ ëŒ€ê¸° ì‹œê°„
    
    Returns:
        [command, send_to, comment, result]
    """
    voice_io = get_voice_io()
    result = None
    
    if command == "listen":
        # í•œ ë²ˆ ìŒì„± ì…ë ¥
        recognized_text = voice_io.listen_once(language=language, timeout=timeout)
        result = {
            "status": "success" if recognized_text else "no_input",
            "text": recognized_text,
            "message": f"ì¸ì‹ë¨: {recognized_text}" if recognized_text else "ìŒì„± ì…ë ¥ ì—†ìŒ"
        }
    
    elif command == "speak":
        # í…ìŠ¤íŠ¸ ìŒì„± ì¶œë ¥
        if not text:
            result = {
                "status": "error",
                "message": "ì¶œë ¥í•  í…ìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            }
        else:
            success = voice_io.speak(text)
            result = {
                "status": "success" if success else "error",
                "text": text,
                "message": "ìŒì„± ì¶œë ¥ ì™„ë£Œ" if success else "ìŒì„± ì¶œë ¥ ì‹¤íŒ¨"
            }
    
    elif command == "start_listening":
        # ì—°ì† ë“£ê¸° ëª¨ë“œ ì‹œì‘
        success = voice_io.start_continuous_listening(language=language)
        result = {
            "status": "success" if success else "already_running",
            "message": "ì—°ì† ë“£ê¸° ëª¨ë“œ ì‹œì‘" if success else "ì´ë¯¸ ì‹¤í–‰ ì¤‘"
        }
    
    elif command == "stop_listening":
        # ì—°ì† ë“£ê¸° ëª¨ë“œ ì¤‘ì§€
        success = voice_io.stop_continuous_listening()
        result = {
            "status": "success" if success else "not_running",
            "message": "ì—°ì† ë“£ê¸° ëª¨ë“œ ì¤‘ì§€" if success else "ì‹¤í–‰ ì¤‘ì´ ì•„ë‹˜"
        }
    
    elif command == "get_text":
        # ì¸ì‹ëœ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (ì—°ì† ë“£ê¸° ëª¨ë“œ)
        recognized_text = voice_io.get_recognized_text()
        result = {
            "status": "success" if recognized_text else "no_input",
            "text": recognized_text,
            "message": f"ì¸ì‹ë¨: {recognized_text}" if recognized_text else "ëŒ€ê¸° ì¤‘ì¸ í…ìŠ¤íŠ¸ ì—†ìŒ"
        }
    
    else:
        result = {
            "status": "error",
            "message": f"ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´: {command}"
        }
    
    return [command, send_to, comment, result]


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("=== ìŒì„± ì…ì¶œë ¥ ë„êµ¬ í…ŒìŠ¤íŠ¸ (Whisper Base) ===\n")
    
    # í…ŒìŠ¤íŠ¸ 1: ìŒì„± ì¶œë ¥
    print("1. ìŒì„± ì¶œë ¥ í…ŒìŠ¤íŠ¸")
    result = tool_voice_io("speak", text="ì•ˆë…•í•˜ì„¸ìš”. Whisper Base ëª¨ë¸ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.")
    print(f"ê²°ê³¼: {result}\n")
    
    # í…ŒìŠ¤íŠ¸ 2: ìŒì„± ì…ë ¥
    print("2. ìŒì„± ì…ë ¥ í…ŒìŠ¤íŠ¸ (5ì´ˆ ì•ˆì— ë§ì”€í•˜ì„¸ìš”)")
    result = tool_voice_io("listen", timeout=5)
    print(f"ê²°ê³¼: {result}\n")
    
    # í…ŒìŠ¤íŠ¸ 3: ì—°ì† ë“£ê¸° ëª¨ë“œ
    print("3. ì—°ì† ë“£ê¸° ëª¨ë“œ í…ŒìŠ¤íŠ¸ (10ì´ˆê°„ ì—¬ëŸ¬ ë²ˆ ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    tool_voice_io("start_listening")
    
    for i in range(10):
        time.sleep(1)
        result = tool_voice_io("get_text")
        if result[3]["text"]:
            print(f"ì¸ì‹: {result[3]['text']}")
    
    tool_voice_io("stop_listening")
    print("\ní…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
