"""
tool_magazine.py - í†µí•© ì¡ì§€ ìƒì„± ë„êµ¬

ë‹¤ì–‘í•œ ì •ë³´ ì†ŒìŠ¤ì—ì„œ ì½˜í…ì¸ ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ì¡ì§€ í˜•ì‹ìœ¼ë¡œ ì¡°ë¦½í•©ë‹ˆë‹¤.

ì§€ì› ì†ŒìŠ¤:
- Hacker News: ê¸°ìˆ  íŠ¸ë Œë“œ
- Reddit: ì»¤ë®¤ë‹ˆí‹° í† ë¡ 
- Medium: ì—ì„¸ì´/ì‚¬ìƒ‰
- Google Books: ì±… ì¶”ì²œ

íŠ¹ì§•:
- í•˜ë‚˜ì˜ ë„êµ¬ë¡œ ëª¨ë“  ì†ŒìŠ¤ ê´€ë¦¬
- newspaper.pyì™€ ë™ì¼í•œ êµ¬ì¡°
- Markdown + HTML ìë™ ìƒì„±
- ìŠ¤íƒ ë‹¤ë“œ ë„êµ¬ (í† í° ì ˆì•½)
"""

import os
import json
import re
import requests
from datetime import datetime
from html import unescape
from tool_utils import markdown_to_html, OUTPUTS_DIR


# ì¡ì§€ í”„ë¦¬ì…‹ ì •ì˜
MAGAZINE_PRESETS = {
    "ì£¼ê°„": {
        "title": "IndieBiz ì£¼ê°„ ë§¤ê±°ì§„",
        "sections": [
            {"source": "hackernews", "count": 5},
            {"source": "reddit", "subreddit": "programming", "count": 3},
            {"source": "medium", "topic": "technology", "count": 3},
            {"source": "books", "topic": "ìê¸°ê³„ë°œ", "count": 3}
        ]
    },
    
    "ì—¬í–‰": {
        "title": "IndieBiz ì—¬í–‰ ë§¤ê±°ì§„",
        "sections": [
            {"source": "reddit", "subreddit": "travel", "count": 5},
            {"source": "medium", "topic": "travel", "count": 3},
            {"source": "books", "topic": "ì—¬í–‰", "count": 3}
        ]
    },
    
    "ê¸°ìˆ ": {
        "title": "IndieBiz ê¸°ìˆ  ë§¤ê±°ì§„",
        "sections": [
            {"source": "hackernews", "count": 10},
            {"source": "reddit", "subreddit": "programming", "count": 5},
            {"source": "medium", "topic": "programming", "count": 3}
        ]
    },
    
    "ì² í•™": {
        "title": "IndieBiz ì¸ë¬¸ ë§¤ê±°ì§„",
        "sections": [
            {"source": "reddit", "subreddit": "philosophy", "count": 5},
            {"source": "medium", "topic": "philosophy", "count": 5},
            {"source": "books", "topic": "ì² í•™", "count": 3}
        ]
    },
    
    "ë¬¸í™”": {
        "title": "IndieBiz ë¬¸í™” ë§¤ê±°ì§„",
        "sections": [
            {"source": "reddit", "subreddit": "books", "count": 4},
            {"source": "medium", "topic": "culture", "count": 3},
            {"source": "books", "topic": "ì˜ˆìˆ ", "count": 3}
        ]
    },
    
    "ì¢…í•©": {
        "title": "IndieBiz ì¢…í•© ë§¤ê±°ì§„",
        "sections": [
            {"source": "hackernews", "count": 5},
            {"source": "reddit", "subreddit": "science", "count": 3},
            {"source": "reddit", "subreddit": "AI", "count": 3},
            {"source": "medium", "topic": "technology", "count": 3},
            {"source": "medium", "topic": "life", "count": 3},
            {"source": "books", "topic": "ì¸ê³µì§€ëŠ¥", "count": 3},
            {"source": "books", "topic": "ë‡Œê³¼í•™", "count": 3},
            {"source": "books", "topic": "ê±´ì¶•", "count": 3},
        ]
    }
}


def clean_html(text: str) -> str:
    """HTML íƒœê·¸ ì™„ì „ ì œê±° ë° ì—”í‹°í‹° ë””ì½”ë”©"""
    if not text:
        return ""
    
    text = re.sub(r'<[^>]+>', '', text)
    text = unescape(text)
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text


def fetch_hackernews(count: int = 5) -> dict:
    """
    Hacker News ìµœì‹  ì¸ê¸° ê¸€ ê°€ì ¸ì˜¤ê¸°
    
    Args:
        count: ê°€ì ¸ì˜¬ ê¸€ ê°œìˆ˜
    
    Returns:
        {'success': bool, 'items': list}
    """
    print(f"   ğŸ”¥ Hacker News Top {count} ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
    
    try:
        # Top Stories API
        response = requests.get(
            'https://hacker-news.firebaseio.com/v0/topstories.json',
            timeout=10
        )
        
        if response.status_code != 200:
            return {'success': False, 'items': []}
        
        story_ids = response.json()[:count]
        items = []
        
        for story_id in story_ids:
            try:
                item_response = requests.get(
                    f'https://hacker-news.firebaseio.com/v0/item/{story_id}.json',
                    timeout=5
                )
                
                if item_response.status_code == 200:
                    item_data = item_response.json()
                    
                    items.append({
                        'title': item_data.get('title', ''),
                        'url': item_data.get('url', f'https://news.ycombinator.com/item?id={story_id}'),
                        'points': item_data.get('score', 0),
                        'comments': item_data.get('descendants', 0),
                        'author': item_data.get('by', 'unknown'),
                        'time': datetime.fromtimestamp(item_data.get('time', 0)).strftime('%Y-%m-%d %H:%M')
                    })
            except Exception as e:
                print(f"      âš ï¸  í•­ëª© {story_id} ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
                continue
        
        print(f"      âœ“ {len(items)}ê°œ ê°€ì ¸ì˜´")
        return {'success': True, 'items': items}
    
    except Exception as e:
        print(f"      âŒ Hacker News ì—ëŸ¬: {e}")
        return {'success': False, 'items': []}


def fetch_reddit(subreddit: str = 'programming', count: int = 5) -> dict:
    """
    Reddit ì¸ê¸° í¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    
    Args:
        subreddit: ì„œë¸Œë ˆë”§ ì´ë¦„ (ì˜ˆ: 'programming', 'travel', 'books')
        count: ê°€ì ¸ì˜¬ í¬ìŠ¤íŠ¸ ê°œìˆ˜
    
    Returns:
        {'success': bool, 'items': list}
    """
    print(f"   ğŸ¤– Reddit r/{subreddit} Top {count} ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
    
    try:
        # Reddit JSON API (ì¸ì¦ ë¶ˆí•„ìš”)
        url = f'https://www.reddit.com/r/{subreddit}/hot.json'
        headers = {'User-Agent': 'IndieBiz Magazine Bot 1.0'}
        
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code != 200:
            return {'success': False, 'items': []}
        
        data = response.json()
        posts = data.get('data', {}).get('children', [])
        
        if not posts:
            return {'success': False, 'items': []}
        
        items = []
        for post_data in posts[:count]:
            post = post_data.get('data', {})
            
            # ìì²´ í…ìŠ¤íŠ¸ ë˜ëŠ” ë§í¬
            is_self = post.get('is_self', False)
            post_url = f"https://www.reddit.com{post.get('permalink', '')}" if is_self else post.get('url', '')
            
            # ë³¸ë¬¸ ìš”ì•½
            selftext = post.get('selftext', '')
            if selftext and len(selftext) > 300:
                selftext = selftext[:300] + '...'
            
            items.append({
                'title': post.get('title', ''),
                'author': post.get('author', 'unknown'),
                'url': post_url,
                'score': post.get('score', 0),
                'num_comments': post.get('num_comments', 0),
                'created': datetime.fromtimestamp(post.get('created_utc', 0)).strftime('%Y-%m-%d'),
                'selftext': selftext,
                'is_self': is_self
            })
        
        print(f"      âœ“ {len(items)}ê°œ ê°€ì ¸ì˜´")
        return {'success': True, 'items': items}
    
    except Exception as e:
        print(f"      âŒ Reddit ì—ëŸ¬: {e}")
        return {'success': False, 'items': []}


def fetch_medium(topic: str = 'philosophy', count: int = 3) -> dict:
    """
    Medium ì—ì„¸ì´ ê°€ì ¸ì˜¤ê¸° (RSS í”¼ë“œ)
    
    Args:
        topic: ì£¼ì œ íƒœê·¸
        count: ê°€ì ¸ì˜¬ ê¸€ ê°œìˆ˜
    
    Returns:
        {'success': bool, 'items': list}
    """
    print(f"   âœï¸  Medium '{topic}' ì—ì„¸ì´ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
    
    try:
        import feedparser
        from urllib.parse import quote
        
        # Medium íƒœê·¸ RSS (URL ì¸ì½”ë”© ì ìš©)
        encoded_topic = quote(topic)
        feed_url = f'https://medium.com/feed/tag/{encoded_topic}'
        
        feed = feedparser.parse(feed_url)
        
        if not feed.entries:
            return {'success': False, 'items': []}
        
        items = []
        for entry in feed.entries[:count]:
            # ìš”ì•½ ì¶”ì¶œ (HTML ì œê±°)
            summary = clean_html(entry.get('summary', ''))
            if len(summary) > 300:
                summary = summary[:300] + '...'
            
            items.append({
                'title': entry.get('title', ''),
                'author': entry.get('author', 'Unknown'),
                'url': entry.get('link', ''),
                'published': entry.get('published', ''),
                'summary': summary
            })
        
        print(f"      âœ“ {len(items)}ê°œ ê°€ì ¸ì˜´")
        return {'success': True, 'items': items}
    
    except ImportError:
        print("      âš ï¸  feedparser ì„¤ì¹˜ í•„ìš”: pip install feedparser")
        return {'success': False, 'items': []}
    except Exception as e:
        print(f"      âŒ Medium ì—ëŸ¬: {e}")
        return {'success': False, 'items': []}


def fetch_google_books(topic: str, count: int = 3) -> dict:
    """
    Google Books ê²€ìƒ‰
    
    Args:
        topic: ê²€ìƒ‰ ì£¼ì œ
        count: ê°€ì ¸ì˜¬ ì±… ê°œìˆ˜
    
    Returns:
        {'success': bool, 'items': list}
    """
    print(f"   ğŸ“š Google Books '{topic}' ê²€ìƒ‰ ì¤‘...")
    
    try:
        api_url = 'https://www.googleapis.com/books/v1/volumes'
        
        params = {
            'q': topic,
            'maxResults': count,
            'langRestrict': 'ko',  # í•œêµ­ì–´ ì±…
            'orderBy': 'relevance'
        }
        
        response = requests.get(api_url, params=params, timeout=10)
        
        if response.status_code != 200:
            return {'success': False, 'items': []}
        
        data = response.json()
        
        if 'items' not in data:
            return {'success': False, 'items': []}
        
        items = []
        for item in data['items']:
            volume_info = item.get('volumeInfo', {})
            
            # ì €ì ë¦¬ìŠ¤íŠ¸
            authors = volume_info.get('authors', ['Unknown'])
            author_str = ', '.join(authors)
            
            # ì„¤ëª…
            description = volume_info.get('description', '')
            if description:
                description = clean_html(description)
                if len(description) > 200:
                    description = description[:200] + '...'
            
            items.append({
                'title': volume_info.get('title', ''),
                'authors': author_str,
                'publisher': volume_info.get('publisher', ''),
                'published_date': volume_info.get('publishedDate', ''),
                'description': description,
                'thumbnail': volume_info.get('imageLinks', {}).get('thumbnail', ''),
                'info_link': volume_info.get('infoLink', '')
            })
        
        print(f"      âœ“ {len(items)}ê°œ ì°¾ìŒ")
        return {'success': True, 'items': items}
    
    except Exception as e:
        print(f"      âŒ Google Books ì—ëŸ¬: {e}")
        return {'success': False, 'items': []}


def generate_section_hackernews(count: int = 5) -> dict:
    """Hacker News ì„¹ì…˜ ìƒì„±"""
    result = fetch_hackernews(count)
    
    if not result['success'] or not result['items']:
        return {
            'success': False,
            'markdown': "## ğŸ”¥ Hacker News\n\në°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n---\n\n"
        }
    
    section = "## ğŸ”¥ Hacker News\n\n"
    
    for i, item in enumerate(result['items'], 1):
        section += f"### {i}. {item['title']}\n\n"
        section += f"**{item['points']} points** | {item['comments']} comments | by {item['author']}\n\n"
        section += f"ğŸ”— [Read More]({item['url']})\n\n"
        section += "---\n\n"
    
    return {'success': True, 'markdown': section, 'count': len(result['items'])}


def generate_section_reddit(subreddit: str, count: int = 5) -> dict:
    """Reddit ì„¹ì…˜ ìƒì„±"""
    result = fetch_reddit(subreddit, count)
    
    if not result['success'] or not result['items']:
        return {
            'success': False,
            'markdown': f"## ğŸ¤– Reddit: r/{subreddit}\n\ní¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n---\n\n"
        }
    
    section = f"## ğŸ¤– Reddit: r/{subreddit}\n\n"
    
    for i, item in enumerate(result['items'], 1):
        section += f"### {i}. {item['title']}\n\n"
        section += f"**{item['score']} upvotes** | {item['num_comments']} comments | by u/{item['author']}\n\n"
        
        # ìì²´ ê¸€ì´ë©´ ë³¸ë¬¸ ì¼ë¶€ í¬í•¨
        if item['selftext']:
            section += f"{item['selftext']}\n\n"
        
        section += f"ğŸ”— [Read More]({item['url']})\n\n"
        section += "---\n\n"
    
    return {'success': True, 'markdown': section, 'count': len(result['items'])}


def generate_section_medium(topic: str, count: int = 3) -> dict:
    """Medium ì„¹ì…˜ ìƒì„±"""
    result = fetch_medium(topic, count)
    
    if not result['success'] or not result['items']:
        return {
            'success': False,
            'markdown': f"## âœï¸ Medium: {topic}\n\nì—ì„¸ì´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n---\n\n"
        }
    
    section = f"## âœï¸ Medium: {topic}\n\n"
    
    for i, item in enumerate(result['items'], 1):
        section += f"### {i}. {item['title']}\n\n"
        section += f"**by {item['author']}** | {item['published']}\n\n"
        
        if item['summary']:
            section += f"{item['summary']}\n\n"
        
        section += f"ğŸ”— [Read on Medium]({item['url']})\n\n"
        section += "---\n\n"
    
    return {'success': True, 'markdown': section, 'count': len(result['items'])}


def generate_section_books(topic: str, count: int = 3) -> dict:
    """Google Books ì„¹ì…˜ ìƒì„±"""
    result = fetch_google_books(topic, count)
    
    if not result['success'] or not result['items']:
        return {
            'success': False,
            'markdown': f"## ğŸ“š Books: {topic}\n\nì±…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n---\n\n"
        }
    
    section = f"## ğŸ“š Books: {topic}\n\n"
    
    for i, item in enumerate(result['items'], 1):
        section += f"### {i}. {item['title']}\n\n"
        section += f"**ì €ì**: {item['authors']}"
        
        if item['publisher']:
            section += f" | **ì¶œíŒ**: {item['publisher']}"
        
        if item['published_date']:
            section += f" | **ë°œí–‰**: {item['published_date']}"
        
        section += "\n\n"
        
        if item['description']:
            section += f"{item['description']}\n\n"
        
        section += f"ğŸ”— [More Info]({item['info_link']})\n\n"
        section += "---\n\n"
    
    return {'success': True, 'markdown': section, 'count': len(result['items'])}


def assemble_magazine(title: str, date_str: str, sections: list) -> str:
    """
    ì„¹ì…˜ë“¤ì„ ì¡°ë¦½í•˜ì—¬ ì™„ì„±ëœ ì¡ì§€ ìƒì„±
    """
    # ëª©ì°¨ ìƒì„±
    toc_items = []
    for section in sections:
        if section.get('success') and section.get('count', 0) > 0:
            name = section.get('name', 'Unknown')
            count = section.get('count', 0)
            toc_items.append(f"- {name} ({count}ê°œ)")
    
    toc = "\n".join(toc_items) if toc_items else "- (ë‚´ìš© ì—†ìŒ)"
    
    # ì„¹ì…˜ ë‚´ìš© ê²°í•©
    content = "\n\n".join([s['markdown'] for s in sections if s.get('success')])
    
    # í†µê³„
    total_items = sum(s.get('count', 0) for s in sections if s.get('success'))
    
    # ìµœì¢… ì¡ì§€
    magazine = f"""# {title}

**ë°œí–‰ì¼**: {date_str}  
**ë°œí–‰ì²˜**: IndieBiz Magazine System  
**ì´ í•­ëª©**: {total_items}ê°œ

---

## ğŸ“‘ ëª©ì°¨

{toc}

---

{content}

---

## ğŸ“Š ì œì‘ ì •ë³´

- **ìƒì„± ì‹œê°**: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}
- **ì„¹ì…˜ ìˆ˜**: {len([s for s in sections if s.get('success')])}ê°œ
- **ì´ í•­ëª©**: {total_items}ê°œ
- **AI ì‚¬ìš©**: ì—†ìŒ (í† í° ì†Œë¹„ 0)
"""
    
    return magazine


def generate_magazine(preset: str = None, sections: list = None, title: str = None) -> dict:
    """
    í†µí•© ì¡ì§€ ìƒì„±
    
    Args:
        preset: í”„ë¦¬ì…‹ ì´ë¦„ ('ì£¼ê°„', 'ì—¬í–‰', 'ê¸°ìˆ ', 'ì² í•™', 'ë¬¸í™”', 'ì¢…í•©')
        sections: ìˆ˜ë™ ì„¹ì…˜ ì„¤ì • (preset ëŒ€ì‹  ì‚¬ìš©)
        title: ì¡ì§€ ì œëª© (ì„ íƒì‚¬í•­)
    
    Returns:
        ìƒì„± ê²°ê³¼
    """
    
    # í”„ë¦¬ì…‹ ì²˜ë¦¬
    if preset:
        if preset not in MAGAZINE_PRESETS:
            return {
                'success': False,
                'message': f"ì¡ì§€ ìƒì„± ì‹¤íŒ¨: ì•Œ ìˆ˜ ì—†ëŠ” í”„ë¦¬ì…‹ '{preset}'. ì‚¬ìš© ê°€ëŠ¥: {', '.join(MAGAZINE_PRESETS.keys())}",
                'next_action': 'ì´ ì˜¤ë¥˜ ê²°ê³¼ë¥¼ ìš”ì²­ìì—ê²Œ call_agentë¡œ ì „ë‹¬í•˜ì„¸ìš”.'
            }
        
        preset_data = MAGAZINE_PRESETS[preset]
        sections_config = preset_data['sections'].copy()
        magazine_title = title if title else preset_data['title']
        
        print(f"ğŸ“Œ í”„ë¦¬ì…‹ ì‚¬ìš©: {preset}")
    
    elif sections:
        # ìˆ˜ë™ ì„¤ì •
        sections_config = sections
        magazine_title = title if title else 'IndieBiz Magazine'
    
    else:
        return {
            'success': False,
            'message': 'ì¡ì§€ ìƒì„± ì‹¤íŒ¨: preset ë˜ëŠ” sections ì¤‘ í•˜ë‚˜ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.',
            'next_action': 'ì´ ì˜¤ë¥˜ ê²°ê³¼ë¥¼ ìš”ì²­ìì—ê²Œ call_agentë¡œ ì „ë‹¬í•˜ì„¸ìš”.'
        }
    
    # ë‚ ì§œ
    today = datetime.now()
    date_str = today.strftime('%Yë…„ %mì›” %dì¼')
    date_filename = today.strftime('%Y%m%d')
    
    print(f"\nğŸ“š ì¡ì§€ ì œì‘ ì‹œì‘: {magazine_title} ({date_str})")
    print(f"ğŸ“‹ ì„¹ì…˜ ìˆ˜: {len(sections_config)}ê°œ\n")
    
    # ê° ì„¹ì…˜ ìƒì„±
    sections = []
    
    for i, section_config in enumerate(sections_config, 1):
        source = section_config.get('source')
        print(f"[{i}/{len(sections_config)}]", end=" ")
        
        if source == 'hackernews':
            count = section_config.get('count', 5)
            section = generate_section_hackernews(count)
            section['name'] = 'Hacker News'
            
        elif source == 'reddit':
            subreddit = section_config.get('subreddit', 'programming')
            count = section_config.get('count', 5)
            section = generate_section_reddit(subreddit, count)
            section['name'] = f'Reddit: r/{subreddit}'
            
        elif source == 'medium':
            topic = section_config.get('topic', 'philosophy')
            count = section_config.get('count', 3)
            section = generate_section_medium(topic, count)
            section['name'] = f'Medium: {topic}'
            
        elif source == 'books':
            topic = section_config.get('topic', 'ì—¬í–‰')
            count = section_config.get('count', 3)
            section = generate_section_books(topic, count)
            section['name'] = f'Books: {topic}'
        
        else:
            print(f"âš ï¸  ì•Œ ìˆ˜ ì—†ëŠ” ì†ŒìŠ¤: {source}")
            continue
        
        sections.append(section)
    
    print(f"\nâœ… ëª¨ë“  ì„¹ì…˜ ìƒì„± ì™„ë£Œ!\n")
    
    # ì¡ì§€ ì¡°ë¦½
    print("ğŸ“ ì¡ì§€ ì¡°ë¦½ ì¤‘...")
    final_magazine = assemble_magazine(magazine_title, date_str, sections)

    # HTML ë³€í™˜ ë° ì €ì¥
    print("ğŸŒ HTML ë³€í™˜ ì¤‘...")
    os.makedirs(OUTPUTS_DIR, exist_ok=True)

    html_content = markdown_to_html(final_magazine, magazine_title, date_str, doc_type="magazine")
    html_filename = f"ì¡ì§€_{date_filename}.html"
    html_filepath = os.path.join(OUTPUTS_DIR, html_filename)

    with open(html_filepath, 'w', encoding='utf-8') as f:
        f.write(html_content)

    print(f"ğŸ’¾ HTML ì €ì¥: {html_filename}\n")
    
    # í†µê³„
    total_items = sum(s.get('count', 0) for s in sections if s.get('success'))
    
    return {
        'success': True,
        'message': f'ì¡ì§€ ìƒì„± ì™„ë£Œ. íŒŒì¼: {html_filepath}',
        'next_action': 'ì´ ê²°ê³¼ë¥¼ ìš”ì²­ìì—ê²Œ call_agentë¡œ ì „ë‹¬í•˜ì„¸ìš”.'
    }


# generate_magazine_standard ì œê±°ë¨ - ë‹¨ìˆœ íŒŒì¼ ì €ì¥ë§Œ ìˆ˜í–‰


# AIì—ê²Œ ì œê³µí•  ë„êµ¬ ì •ì˜
MAGAZINE_TOOLS = [
    {
        "name": "generate_magazine",
        "description": """ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ì¡ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

í”„ë¦¬ì…‹:
- "ì£¼ê°„": ê¸°ìˆ  íŠ¸ë Œë“œ + Reddit í† ë¡  + ì—ì„¸ì´ + ì±…
- "ì—¬í–‰": Reddit ì—¬í–‰ + ì—ì„¸ì´ + ì±…
- "ê¸°ìˆ ": IT ë‰´ìŠ¤ + Reddit í”„ë¡œê·¸ë˜ë° + ì—ì„¸ì´
- "ì² í•™": Reddit ì² í•™ + ì² í•™ ì—ì„¸ì´ + ì±…
- "ë¬¸í™”": Reddit ì±… í† ë¡  + ë¬¸í™” ì—ì„¸ì´ + ì˜ˆìˆ  ì±…
- "ì¢…í•©": ê¸°ìˆ  + Reddit ê³¼í•™ + ì—ì„¸ì´ + ì±…

íŠ¹ì§•:
- í”„ë¦¬ì…‹ìœ¼ë¡œ ê°„ë‹¨í•˜ê²Œ ì‚¬ìš©
- Markdown + HTML ìë™ ìƒì„±
- AI ì‚¬ìš© ì•ˆ í•¨ (í† í° 0)

ì‚¬ìš© ì˜ˆì‹œ:
1. ê°„ë‹¨: generate_magazine(preset="ì£¼ê°„")
2. ìˆ˜ë™: generate_magazine(sections=[{"source": "hackernews", "count": 5}])""",
        "input_schema": {
            "type": "object",
            "properties": {
                "preset": {
                    "type": "string",
                    "enum": ["ì£¼ê°„", "ì—¬í–‰", "ê¸°ìˆ ", "ì² í•™", "ë¬¸í™”", "ì¢…í•©"],
                    "description": "ì¡ì§€ í”„ë¦¬ì…‹ (ê°„ë‹¨ ì‚¬ìš©)"
                },
                "sections": {
                    "type": "array",
                    "description": "ìˆ˜ë™ ì„¤ì •: ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸ (preset ëŒ€ì‹  ì‚¬ìš©)",
                    "items": {
                        "type": "object",
                        "properties": {
                            "source": {
                                "type": "string",
                                "enum": ["hackernews", "reddit", "medium", "books"],
                                "description": "ì •ë³´ ì†ŒìŠ¤"
                            },
                            "count": {
                                "type": "integer",
                                "description": "ê°€ì ¸ì˜¬ í•­ëª© ìˆ˜"
                            },
                            "subreddit": {
                                "type": "string",
                                "description": "ì„œë¸Œë ˆë”§ ì´ë¦„ (reddit ì†ŒìŠ¤ ì‚¬ìš© ì‹œ)"
                            },
                            "topic": {
                                "type": "string",
                                "description": "ì£¼ì œ (medium, books)"
                            }
                        },
                        "required": ["source"]
                    }
                },
                "title": {
                    "type": "string",
                    "description": "ì¡ì§€ ì œëª© (ì„ íƒì‚¬í•­)"
                }
            },
            "required": []
        }
    }
]


if __name__ == "__main__":
    # í”„ë¦¬ì…‹ í…ŒìŠ¤íŠ¸
    print("=== ì¡ì§€ ìƒì„± í…ŒìŠ¤íŠ¸ (í”„ë¦¬ì…‹) ===\n")
    
    result = generate_magazine(preset="ì£¼ê°„")
    print(f"\nê²°ê³¼: {result['message']}")
