"""
tool_newspaper.py - ì‹ ë¬¸ ìë™ ìƒì„± ë„êµ¬ (Google News ë²„ì „)

í‚¤ì›Œë“œë¥¼ ì…ë ¥ë°›ì•„ ê° í‚¤ì›Œë“œë³„ë¡œ Google News ê²€ìƒ‰ì„ ì‹¤í–‰í•˜ê³ 
ê²°ê³¼ë¥¼ ì‹ ë¬¸ í˜•ì‹ìœ¼ë¡œ ì¡°ë¦½í•©ë‹ˆë‹¤.

íŠ¹ì§•:
- AI ì‚¬ìš© ì•ˆ í•¨ (í† í° ì†Œë¹„ 0)
- ì‹¤ì œ ë‰´ìŠ¤ë§Œ (ê°€ì§œ ì—†ìŒ)
- Google News RSS ê¸°ë°˜
- Pythonìœ¼ë¡œ ì¡°ë¦½

ìŠ¤íƒ ë‹¤ë“œ ë„êµ¬: OutputRouterë¥¼ í†µí•´ ë¼ìš°íŒ…
"""

import os
import json
import re
from html import unescape
from datetime import datetime
from tool_google_news import search_google_news
from tool_utils import markdown_to_html, OUTPUTS_DIR


def clean_html(text: str) -> str:
    """HTML íƒœê·¸ ì™„ì „ ì œê±° ë° ì—”í‹°í‹° ë””ì½”ë”©"""
    if not text:
        return ""
    
    # HTML íƒœê·¸ ì œê±°
    text = re.sub(r'<[^>]+>', '', text)
    
    # HTML ì—”í‹°í‹° ë””ì½”ë”©
    text = unescape(text)
    
    # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text


def generate_section(keyword: str, news_count: int = 7, exclude_sources: list = None) -> dict:
    """
    í‚¤ì›Œë“œë¡œ Google News ê²€ìƒ‰í•˜ì—¬ ì„¹ì…˜ ìƒì„±
    
    Args:
        keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
        news_count: ë‰´ìŠ¤ ê°œìˆ˜ (ê¸°ë³¸ 7ê°œ)
        exclude_sources: ì œì™¸í•  ì–¸ë¡ ì‚¬ ëª©ë¡ (ì˜ˆ: ['ì¡°ì„ ì¼ë³´', 'ë§¤ì¼ê²½ì œ'])
    
    Returns:
        {
            'keyword': str,
            'markdown': str,
            'news_count': int,
            'success': bool
        }
    """
    print(f"   ğŸ“° '{keyword}' ì„¹ì…˜ ìƒì„± ì¤‘...")
    
    if exclude_sources is None:
        exclude_sources = []
    
    # Google News ê²€ìƒ‰ (ë” ë§ì´ ê°€ì ¸ì™€ì„œ í•„í„°ë§ í›„ ì¶©ë¶„í•œ ìˆ˜ í™•ë³´)
    fetch_count = news_count * 3 if exclude_sources else news_count
    result = search_google_news(query=keyword, count=fetch_count, language='ko')
    
    # ê²°ê³¼ íŒŒì¼ ì½ê¸°
    if result['success']:
        with open(result['file'], 'r', encoding='utf-8') as f:
            data = json.load(f)
            result['results'] = data.get('results', [])
    else:
        result['results'] = []
    
    if not result['success'] or not result['results']:
        print(f"      âš ï¸  ë‰´ìŠ¤ ì—†ìŒ")
        return {
            'keyword': keyword,
            'markdown': f"## {keyword}\n\në‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n---\n\n",
            'news_count': 0,
            'success': False
        }
    
    # ì œì™¸í•  ì–¸ë¡ ì‚¬ í•„í„°ë§
    filtered_results = []
    excluded_count = 0
    
    for item in result['results']:
        source = item.get('source', '')
        
        # ì œì™¸ ëª©ë¡ì— ìˆëŠ”ì§€ í™•ì¸ (ë¶€ë¶„ ë§¤ì¹­)
        is_excluded = False
        for exclude in exclude_sources:
            if exclude in source:
                is_excluded = True
                excluded_count += 1
                break
        
        if not is_excluded:
            filtered_results.append(item)
            
            # í•„ìš”í•œ ìˆ˜ë§Œí¼ ëª¨ì•˜ìœ¼ë©´ ì¤‘ë‹¨
            if len(filtered_results) >= news_count:
                break
    
    if excluded_count > 0:
        print(f"      ğŸš« ì œì™¸ë¨: {excluded_count}ê°œ ({', '.join(exclude_sources)})")
    
    if not filtered_results:
        print(f"      âš ï¸  í•„í„°ë§ í›„ ë‰´ìŠ¤ ì—†ìŒ")
        return {
            'keyword': keyword,
            'markdown': f"## {keyword}\n\ní•„í„°ë§ í›„ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n---\n\n",
            'news_count': 0,
            'success': False
        }
    
    # Markdown ì„¹ì…˜ ìƒì„±
    section = f"## ğŸ“° {keyword}\n\n"
    
    for i, item in enumerate(filtered_results, 1):
        section += f"### {i}. {item['title']}\n\n"
        section += f"**ì¶œì²˜**: {item['source']} | **ë°œí–‰**: {item['published']}\n\n"
        
        # ìš”ì•½ì´ ìˆê³  ì œëª©ê³¼ ë‹¤ë¥´ë©´ ì¶”ê°€
        if item.get('summary'):
            summary = clean_html(item['summary'])
            if summary and summary != item['title']:
                section += f"{summary}\n\n"
        
        section += f"ğŸ”— [ê¸°ì‚¬ ë³´ê¸°]({item['url']})\n\n"
        section += "---\n\n"
    
    print(f"      âœ“ {len(filtered_results)}ê°œ ë‰´ìŠ¤")
    
    return {
        'keyword': keyword,
        'markdown': section,
        'news_count': len(filtered_results),
        'excluded_count': excluded_count,
        'success': True
    }


def assemble_newspaper(title: str, date_str: str, sections: list) -> str:
    """
    ì„¹ì…˜ë“¤ì„ ì¡°ë¦½í•˜ì—¬ ì™„ì„±ëœ ì‹ ë¬¸ ìƒì„±
    
    Args:
        title: ì‹ ë¬¸ ì œëª©
        date_str: ë°œí–‰ì¼
        sections: ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        ì™„ì„±ëœ Markdown ì‹ ë¬¸
    """
    # ëª©ì°¨ ìƒì„±
    toc_items = []
    for section in sections:
        if section['success'] and section['news_count'] > 0:
            keyword = section['keyword']
            count = section['news_count']
            toc_items.append(f"- [{keyword}](#{keyword}) ({count}ê°œ)")
    
    toc = "\n".join(toc_items)
    
    # ì„¹ì…˜ ë‚´ìš© ê²°í•©
    content = "\n\n".join([s['markdown'] for s in sections])
    
    # í†µê³„
    total_news = sum(s['news_count'] for s in sections)
    
    # ìµœì¢… ì‹ ë¬¸
    newspaper = f"""# {title}

**ë°œí–‰ì¼**: {date_str}  
**ë°œí–‰ì²˜**: IndieBiz AI ì‹ ë¬¸ ì‹œìŠ¤í…œ  
**ì´ ë‰´ìŠ¤**: {total_news}ê°œ

---

## ğŸ“‘ ëª©ì°¨

{toc}

---

{content}

---

## ğŸ“Š ì œì‘ ì •ë³´

- **ìƒì„± ì‹œê°**: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}
- **ì„¹ì…˜ ìˆ˜**: {len(sections)}ê°œ
- **ì´ ë‰´ìŠ¤**: {total_news}ê°œ
- **ì¶œì²˜**: Google News RSS
- **AI ì‚¬ìš©**: ì—†ìŒ (í† í° ì†Œë¹„ 0)
- **ë°©ì‹**: í‚¤ì›Œë“œë³„ Google News ê²€ìƒ‰ â†’ Python ì¡°ë¦½
"""

    return newspaper


def generate_newspaper(keywords: list, title: str = "IndieBiz Daily", exclude_sources: list = None) -> dict:
    """
    Google News ê¸°ë°˜ ì‹ ë¬¸ ìë™ ìƒì„± (AI ì‚¬ìš© ì•ˆ í•¨)
    
    Args:
        keywords: ì„¹ì…˜ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["í•œêµ­", "AI", "ê²½ì œ"])
        title: ì‹ ë¬¸ ì œëª© (ê¸°ë³¸ê°’: "IndieBiz Daily")
        exclude_sources: ì œì™¸í•  ì–¸ë¡ ì‚¬ ëª©ë¡ (ì˜ˆ: ["ì¡°ì„ ì¼ë³´", "ë§¤ì¼ê²½ì œ"])
    
    Returns:
        ìƒì„± ê²°ê³¼
    """
    
    # í‚¤ì›Œë“œ ê²€ì¦
    if not keywords:
        return {
            'success': False,
            'message': 'ì‹ ë¬¸ ìƒì„± ì‹¤íŒ¨: í‚¤ì›Œë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.',
            'next_action': 'ì´ ì˜¤ë¥˜ ê²°ê³¼ë¥¼ ìš”ì²­ìì—ê²Œ call_agentë¡œ ì „ë‹¬í•˜ì„¸ìš”.'
        }
    
    if exclude_sources is None:
        exclude_sources = []
    
    # 1. í˜„ì¬ ë‚ ì§œ
    today = datetime.now()
    date_str = today.strftime('%Yë…„ %mì›” %dì¼')
    date_filename = today.strftime('%Y%m%d')
    
    print(f"\nğŸ“° ì‹ ë¬¸ ì œì‘ ì‹œì‘: {title} ({date_str})")
    print(f"ğŸ“‹ ì„¹ì…˜ ìˆ˜: {len(keywords)}ê°œ")
    print(f"ğŸ”– í‚¤ì›Œë“œ: {', '.join(keywords)}")
    print(f"ğŸ” ì¶œì²˜: Google News RSS")
    if exclude_sources:
        print(f"ğŸš« ì œì™¸: {', '.join(exclude_sources)}")
    print()
    
    # 2. ê° í‚¤ì›Œë“œë³„ë¡œ ì„¹ì…˜ ìƒì„± (Google News ê²€ìƒ‰)
    sections = []
    total_excluded = 0
    
    for i, keyword in enumerate(keywords, 1):
        print(f"[{i}/{len(keywords)}]", end=" ")
        section = generate_section(keyword, news_count=7, exclude_sources=exclude_sources)
        sections.append(section)
        total_excluded += section.get('excluded_count', 0)
    
    print(f"\nâœ… ëª¨ë“  ì„¹ì…˜ ìƒì„± ì™„ë£Œ!")
    if total_excluded > 0:
        print(f"ğŸš« ì´ {total_excluded}ê°œ ê¸°ì‚¬ ì œì™¸ë¨\n")
    
    # 3. ì‹ ë¬¸ ì¡°ë¦½ (Python)
    print("ğŸ“ ì‹ ë¬¸ ì¡°ë¦½ ì¤‘...")
    final_newspaper = assemble_newspaper(title, date_str, sections)

    # 4. HTML ë³€í™˜ ë° ì €ì¥
    print("ğŸŒ HTML ë³€í™˜ ì¤‘...")
    os.makedirs(OUTPUTS_DIR, exist_ok=True)

    html_content = markdown_to_html(final_newspaper, title, date_str, doc_type="newspaper")
    html_filename = f"ì‹ ë¬¸_{date_filename}_{len(keywords)}ë©´.html"
    html_filepath = os.path.join(OUTPUTS_DIR, html_filename)

    with open(html_filepath, 'w', encoding='utf-8') as f:
        f.write(html_content)

    print(f"ğŸ’¾ HTML ì €ì¥: {html_filename}\n")
    
    # 6. í†µê³„
    total_news = sum(s['news_count'] for s in sections)
    
    # 7. ê²°ê³¼ ë°˜í™˜
    return {
        'success': True,
        'message': f'ì‹ ë¬¸ ìƒì„± ì™„ë£Œ. íŒŒì¼: {html_filepath}',
        'next_action': 'ì´ ê²°ê³¼ë¥¼ ìš”ì²­ìì—ê²Œ call_agentë¡œ ì „ë‹¬í•˜ì„¸ìš”.'
    }



NEWSPAPER_TOOLS = [
    {
        "name": "generate_newspaper",
        "description": "Google News ê¸°ë°˜ ì‹ ë¬¸ì„ ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤. keywords ë°°ì—´ì„ ë°›ì•„ ê° í‚¤ì›Œë“œë³„ë¡œ Google Newsë¥¼ ê²€ìƒ‰í•˜ê³  ì‹ ë¬¸ í˜•ì‹ìœ¼ë¡œ ì¡°ë¦½í•©ë‹ˆë‹¤. ê²°ê³¼ëŠ” outputs/ ë””ë ‰í† ë¦¬ì— HTML íŒŒì¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤.",
        "input_schema": {
            "type": "object",
            "properties": {
                "keywords": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "ì‹ ë¬¸ ì„¹ì…˜ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸"
                },
                "title": {
                    "type": "string",
                    "description": "ì‹ ë¬¸ ì œëª© (ê¸°ë³¸: IndieBiz Daily)"
                },
                "exclude_sources": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "ì œì™¸í•  ì–¸ë¡ ì‚¬ ëª©ë¡"
                }
            },
            "required": ["keywords"]
        }
    }
]


if __name__ == "__main__":
    print("=== ì‹ ë¬¸ ìƒì„± í…ŒìŠ¤íŠ¸ ===\n")
    result = generate_newspaper(["í•œêµ­", "AI"], "í…ŒìŠ¤íŠ¸ ì‹ ë¬¸")
    print(f"\nê²°ê³¼: {result['message']}")
